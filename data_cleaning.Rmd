---
title: "Data Cleaning"
author: "ANLY-511-04 Group 3"
date: "12/06/2022"
output:
  html_document: default
---

```{r message = FALSE}
# load libraries for this assignment
library(tidyverse)
library(ggplot2)
library(readxl)
library(knitr)
library(kableExtra)
```

-----

### Functions for Use

```{r}
calculate_proportions <- function(input_df, threshold) {
  
  # create data frame for printing proportions of of NA values
  df <- data.frame(colnames(input_df), round(colMeans(is.na(input_df)), 5), row.names = NULL)
  colnames(df) <- c('Column Name', 'Proportion of Values NA')
  df <- df[order(df$`Proportion of Values NA`, decreasing = TRUE),]
  df_table <- df[df$`Proportion of Values NA` > threshold,]
  
  return (df_table)
}
```

```{r}
print_proportions <- function(input_table) {
  knitr::kable(df_table, row.names = FALSE) %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
}

```

-----

### Read in the Data

Let's first read in the data. We have five files to read in, all by the naming convention of `data/cardataXX.xlsx`, where `XX` $\in$ `{18, 19, 20, 21, 22}`.

```{r warning = FALSE}
# load in the data
cardata2018 <- read_excel('data/cardata2018.xlsx')
cardata2019 <- read_excel('data/cardata2019.xlsx')
cardata2020 <- read_excel('data/cardata2020.xlsx')
cardata2021 <- read_excel('data/cardata2021.xlsx')
cardata2022 <- read_excel('data/cardata2022.xlsx')

# print dimension of data
print(dim(cardata2018))
print(dim(cardata2019))
print(dim(cardata2020))
print(dim(cardata2021))
print(dim(cardata2022))
```

### Observe Properties of the Data

The five datasets come from the same source, but we want to ensure that they are compatible with one-another. The best way to check this is to ensure that the columns are the same across all datasets. If they are, we can easily append the five datasets together, by row, in order to create one, larger dataset.

```{r}
# extract column names for each dataset
colnames2018 <- colnames(cardata2018)
colnames2019 <- colnames(cardata2019)
colnames2020 <- colnames(cardata2020)
colnames2021 <- colnames(cardata2021)
colnames2022 <- colnames(cardata2022)

# ensure that the column names are all the same across all datasets
if ( mean(colnames2018 == colnames2019) == 1 &
     mean(colnames2018 == colnames2020) == 1 &
     mean(colnames2018 == colnames2021) == 1 &
     mean(colnames2018 == colnames2022) == 1 ) {
  print('The column names are the same and in the same order across all five datasets.')
} else {
  print('The column names are NOT the same and in the same order across all five datasets.')
}
```

```{r echo = FALSE}
# remove column names from memory
rm(colnames2018)
rm(colnames2019)
rm(colnames2020)
rm(colnames2021)
rm(colnames2022)
```

Let's append these datasets together since we now that they have the same structure and column names.

```{r}
# bind datasets together by row
cardata <- rbind(cardata2018, cardata2019, cardata2020, cardata2021, cardata2022)
print(dim(cardata))
```

```{r echo = FALSE}
# remove old datasets from memory
rm(cardata2018)
rm(cardata2019)
rm(cardata2020)
rm(cardata2021)
rm(cardata2022)
```

There are also some columns that we are not concerned with for the purpose of our analysis, so we will drop those before proceeding with the cleaning phase. These columns are:

* `Test Vehicle ID`
* `Test Veh Configuration #`
* `Actual Tested Testgroup`
* `Engine Code`
* `Transmission Overdrive Code`
* `Transmission Overdrive Desc`
* `Shift Indicator Light Use Cd`
* `Shift Indicator Light Use Desc`
* `Test Number`
* `Test Originator`
* `Analytically Derived FE?`
* `ADFE Test Number`
* `Test Procedure Cd`
* `Test Procedure Description`
* `Test Fuel Type Cd`
* `Test Category`
* `FE_UNIT`
* `FE Bag 1`
* `FE Bag 2`
* `FE Bag 3`
* `FE Bag 4`

```{r}
# define columns to remove
remove <- c("Test Vehicle ID", 
            "Test Veh Configuration #", 
            "Actual Tested Testgroup", 
            "Engine Code", 
            "Transmission Overdrive Code",
            "Transmission Overdrive Desc",
            "Shift Indicator Light Use Cd",
            "Shift Indicator Light Use Desc",
            "Test Number",
            "Test Originator",
            "Analytically Derived FE?",
            "ADFE Test Number",
            "Test Procedure Cd",
            "Test Procedure Description",
            "Test Fuel Type Cd",
            "Test Category",
            "FE_UNIT",
            "FE Bag 1",
            "FE Bag 2",
            "FE Bag 3",
            "FE Bag 4")

# remove columns and report new shape
cardata <- cardata[, !( colnames(cardata) %in% remove)]
print(dim(cardata))
```

Now, with the columns that we do have, we can observe how many `NA` values exist in each column. We will set a threshold of **10%**; a column with more than 10 percent of its values being `NA` expresses a large number of missing values in our eyes and we will remove it from our analysis. Below, we can see all columns expressing more than 10% of their values as `NA`.

```{r}
# print the proportions of NA values in each column using a threshold of 10%
df_table <- calculate_proportions(cardata, 0.10)
print_proportions(df_table)
```

We can then remove these columns.

```{r}
# remove high-probability NA columns from data frame
remove <- df_table$`Column Name`

# remove columns and report new shape
cardata <- cardata[, !( colnames(cardata) %in% remove)]
print(dim(cardata))
```

We still have columns expressing `NA` values, however. These columns, of course, have less than 10% of their values being `NA`, after the removal performed above. These columns can be seen below.

```{r}
# print the proportions of NA values in each column using a threshold of 0%
df_table <- calculate_proportions(cardata, 0)
print_proportions(df_table)
```

Let's start by observing the first three variables:

* `DT-Inertia Work Ratio Rating`
* `DT-Absolute Speed Change Ratg`
* `DT-Energy Economy Rating`

We can make histograms to see what their distributions are like.

```{r fig.width = 10}
par(mfrow = c(1, 3))
hist(cardata$`DT-Inertia Work Ratio Rating`, main = 'DT-Inertia Work Ratio Rating', breaks = 20)
hist(cardata$`DT-Absolute Speed Change Ratg`, main = 'DT-Absolute Speed Change Rating', breaks = 20)
hist(cardata$`DT-Energy Economy Rating`, main = 'DT-Energy Economy Rating', breaks = 20)
```

It is evident that each of these columns has a set of observations marked with a rating around $100$. This is likely comparable to an `NA` value, as the distribution of values for these attributes is almost entirely hovering around a value of $0$. Let's replace these values with `NA` values so that we don't confuse ourselves with them being valid.

```{r}
# replace high outliers with NA
cardata$`DT-Inertia Work Ratio Rating`[cardata$`DT-Inertia Work Ratio Rating` > 50] <- NA
cardata$`DT-Absolute Speed Change Ratg`[cardata$`DT-Absolute Speed Change Ratg` > 50] <- NA
cardata$`DT-Energy Economy Rating`[cardata$`DT-Energy Economy Rating` > 50] <- NA
```

```{r}
# create data frame for printing proportions of of NA values
df_table <- calculate_proportions(cardata, 0)
print_proportions(df_table)
```

These columns, having been updated by our observations above, now have proportions of missing (or ambiguous) values greater than 10%. Keeping our threshold in mind, we will drop these columns as well.

```{r}
# remove high-probability NA columns from data frame
remove <- df_table$`Column Name`[1:3]

# remove columns and report new shape
cardata <- cardata[, !( colnames(cardata) %in% remove)]
print(dim(cardata))
```

````{r}
# create data frame for printing proportions of of NA values
df_table <- calculate_proportions(cardata, 0)
print_proportions(df_table)
```

### Columns with Null Values

The following three variables have the same number of missing values in the dataset. Let's see if they are from the same rows.

* `DT-Inertia Work Ratio Rating`
* `DT-Absolute Speed Change Ratg`
* `DT-Energy Economy Rating`

```{r eval = FALSE}
# extract row names where these three variables are missing
dti_null <- rownames(cardata[is.na(cardata$`DT-Inertia Work Ratio Rating`), ])
dta_null <- rownames(cardata[is.na(cardata$`DT-Absolute Speed Change Ratg`), ])
dte_null <- rownames(cardata[is.na(cardata$`DT-Energy Economy Rating`), ])

# ensure that the column names are all the same across all datasets
if ( mean(dti_null == dta_null) == 1 &
     mean(dti_null == dte_null) == 1 ) {
  print('These variables are missing in the same rows in the dataset.')
} else {
  print('These variables are missing in different rows in the dataset.')
}
```

```{r eval = FALSE}
hist(cardata$`DT-Energy Economy Rating`)
```

The following two variables have the same number of missing values in the dataset. Let's see if they are from the same rows.

* `Aftertreatment Device Cd`
* `Aftertreatment Device Desc`

```{r}
# extract row names where these three variables are missing
after_cd_null <- rownames(cardata[is.na(cardata$`Aftertreatment Device Cd`), ])
after_desc_null <- rownames(cardata[is.na(cardata$`Aftertreatment Device Desc`), ])

# ensure that the column names are all the same across all datasets
if ( mean(after_cd_null == after_desc_null) == 1 ) {
  print('These variables are missing in the same rows in the dataset.')
} else {
  print('These variables are missing in different rows in the dataset.')
}
```









